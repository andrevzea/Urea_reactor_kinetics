{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import win32com.client as win32  # For COM connection with Aspen Plus\n",
    "import numpy as np  # For numerical calculations\n",
    "import time  # To pause code execution for Aspen run completion\n",
    "import pandas as pd  # To create and manipulate dataframes\n",
    "import matplotlib.pyplot as plt  # For creating plots\n",
    "from SALib.analyze import sobol # For Sobol SA\n",
    "from SALib.sample import sobol as sobol_sample\n",
    "from SALib.sample import saltelli\n",
    "from SALib.test_functions import Ishigami\n",
    "import warnings # To mute warning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Muting warnings\n",
    "warnings.filterwarnings('ignore', category = DeprecationWarning) \n",
    "warnings.filterwarnings('ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency factors using Saltelli sampler\n",
    "factors = {\n",
    "    'num_vars': 3,\n",
    "    'names': ['K1', 'K2', 'K3'],\n",
    "    'bounds': [[1000, 6000],\n",
    "               [10000, 60000],\n",
    "               [100, 600]]\n",
    "}\n",
    "frequency_factor_values = sobol_sample.sample(factors, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to the Aspen simulation\n",
    "Aspenfilepath = r'Template\\Urea_reactor_biuret.bkp'\n",
    "# Access the Aspen Plus simulation\n",
    "Aspen = win32.Dispatch('Apwn.document')\n",
    "Aspen.InitFromArchive2(os.path.abspath(Aspenfilepath))\n",
    "Aspen.Engine.Run2()\n",
    "Aspen.Visible = True # Optional\n",
    "Aspen.SuppressDialogs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Aspen data nodes for different mass fractions and reaction parameters\n",
    "k1_node = r'\\Data\\Reactions\\Reactions\\R1\\Input\\PRE_EXP\\1'\n",
    "k2_node = r'\\Data\\Reactions\\Reactions\\R1\\Input\\PRE_EXP\\2'\n",
    "k3_node = r'\\Data\\Reactions\\Reactions\\R1\\Input\\PRE_EXP\\3'\n",
    "urea_mass_fraction_node = r'\\Data\\Streams\\UREAPROD\\Output\\MASSFRAC\\MIXED\\UREA'\n",
    "carb_mass_fraction_node = r'\\Data\\Streams\\UREAPROD\\Output\\MASSFRAC\\MIXED\\CARB'\n",
    "co2_mass_fraction_node = r'\\Data\\Streams\\UREAPROD\\Output\\MASSFRAC\\MIXED\\CO2'\n",
    "nh3_mass_fraction_node = r'\\Data\\Streams\\UREAPROD\\Output\\MASSFRAC\\MIXED\\NH3'\n",
    "h2o_mass_fraction_node = r'\\Data\\Streams\\UREAPROD\\Output\\MASSFRAC\\MIXED\\H2O'\n",
    "biuret_mass_fraction_node = r'\\Data\\Streams\\UREAPROD\\Output\\MASSFRAC\\MIXED\\BIURETU'\n",
    "run_status_node = r'\\Data\\Results Summary\\Run-Status\\Output\\PER_ERROR\\2'\n",
    "\n",
    "\n",
    "# Initialize lists to store the mass fractions at each K value\n",
    "urea, carb, co2, nh3, h2o, biuret = [], [], [], [], [], []\n",
    "\n",
    "# Initialize list to store k values that arise errors within the Aspen Plus simulation\n",
    "k_errors = []\n",
    "\n",
    "# Loop through each K value, update the Aspen model, and retrieve mass fractions\n",
    "for ki in frequency_factor_values:  \n",
    "    Aspen.Tree.FindNode(k1_node).Value = ki[0]\n",
    "    Aspen.Tree.FindNode(k2_node).Value = ki[1]\n",
    "    Aspen.Tree.FindNode(k3_node).Value = ki[2]\n",
    "    Aspen.Reinit() # Reset the Aspen simulation\n",
    "    Aspen.Engine.Run2() # Run the Aspen simulation\n",
    "    \n",
    "    # Wait until the simulation is finished\n",
    "    while Aspen.Engine.IsRunning == True:\n",
    "        time.sleep(0.7)\n",
    "    \n",
    "    status_message = Aspen.Tree.FindNode(run_status_node).Value # Use status message to check for convergence\n",
    "    # Logic to get values that does not include errors\n",
    "    if 'errors' not in status_message:\n",
    "        urea.append(Aspen.Tree.FindNode(urea_mass_fraction_node).Value)\n",
    "        carb.append(Aspen.Tree.FindNode(carb_mass_fraction_node).Value)\n",
    "        co2.append(Aspen.Tree.FindNode(co2_mass_fraction_node).Value)\n",
    "        nh3.append(Aspen.Tree.FindNode(nh3_mass_fraction_node).Value)\n",
    "        h2o.append(Aspen.Tree.FindNode(h2o_mass_fraction_node).Value)\n",
    "        biuret.append(Aspen.Tree.FindNode(biuret_mass_fraction_node).Value)\n",
    "    else:\n",
    "        k_errors.append([ki[0], ki[1], ki[2]]) # Store k values that get errors\n",
    "        \n",
    "# Close the Aspen Plus connection\n",
    "Aspen.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data into excel files\n",
    "mass_fraction_data = {\n",
    "    'Urea': urea,\n",
    "    'Carb': carb,\n",
    "    'CO2': co2,\n",
    "    'NH3': nh3,\n",
    "    'H2O': h2o,\n",
    "    'Biuret': biuret\n",
    "}\n",
    "\n",
    "k_errors_data = {\n",
    "    'K': k_errors\n",
    "}\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "df_1 = pd.DataFrame(mass_fraction_data)\n",
    "df_2 = pd.DataFrame(k_errors_data)\n",
    "\n",
    "# Saving the DataFrame to an Excel file\n",
    "df_1.to_excel('massfrac.xlsx')\n",
    "df_2.to_excel('kerrors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete k sets that arose errors\n",
    "new_k_errors = []\n",
    "\n",
    "for i in range(0, len(k_errors)):\n",
    "    list = float(k_errors[i][0]), float(k_errors[i][1]), float(k_errors[i][2])\n",
    "    new_k_errors.append(list)\n",
    "\n",
    "matching_indices = [i for i, arr in enumerate(frequency_factor_values) if any(np.array_equal(arr, check) for check in new_k_errors)]\n",
    "filtered_k_values = np.delete(frequency_factor_values, matching_indices, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate percentage error between measured and reference values\n",
    "def Calculate_percentage_error(measured, reference):\n",
    "    return np.abs((measured - reference) / reference) * 100\n",
    "\n",
    "# Define reference mass fractions for comparison (urea, carb, CO2, NH3, H2O, biuret)\n",
    "Reference_mass_frac = np.array([0.322046637078701, 0.265199938619204, 0.0389103609578698, 0.191659325990155, 0.16835012629242, 0.00254959024013388])\n",
    "\n",
    "# Calculate percentage errors for each component\n",
    "Error_urea = Calculate_percentage_error(urea, Reference_mass_frac[0])\n",
    "Error_carb = Calculate_percentage_error(carb, Reference_mass_frac[1])\n",
    "Error_co2 = Calculate_percentage_error(co2, Reference_mass_frac[2])\n",
    "Error_nh3 = Calculate_percentage_error(nh3, Reference_mass_frac[3])\n",
    "Error_h2o = Calculate_percentage_error(h2o, Reference_mass_frac[4])\n",
    "Error_biuret = Calculate_percentage_error(biuret, Reference_mass_frac[5])\n",
    "\n",
    "# Function to compute the group percentage error for each frequency factor\n",
    "def compute_group_percentage_error(Urea, Carb, CO2, NH3, H2O, Biuret, Reference_mass_frac):\n",
    "    # Initialize a list to store the group percentage error for each frequency factor\n",
    "    group_errors = []\n",
    "\n",
    "    # Loop through each frequency factor (row in Urea, Carb, etc.)\n",
    "    for i in range(len(Urea)):\n",
    "        # Calculate percentage errors for all species\n",
    "        error_urea = Calculate_percentage_error(Urea[i], Reference_mass_frac[0])\n",
    "        error_carb = Calculate_percentage_error(Carb[i], Reference_mass_frac[1])\n",
    "        error_co2 = Calculate_percentage_error(CO2[i], Reference_mass_frac[2])\n",
    "        error_nh3 = Calculate_percentage_error(NH3[i], Reference_mass_frac[3])\n",
    "        error_h2o = Calculate_percentage_error(H2O[i], Reference_mass_frac[4])\n",
    "        error_biuret = Calculate_percentage_error(Biuret[i], Reference_mass_frac[5])\n",
    "        \n",
    "        # Combine the errors into a single metric (e.g., mean of all species' errors)\n",
    "        mean_error = np.mean([error_urea, error_carb, error_co2, error_nh3, error_h2o, error_biuret])\n",
    "        \n",
    "        # Append the group error for this frequency factor\n",
    "        group_errors.append(mean_error)\n",
    "    \n",
    "    return np.array(group_errors)\n",
    "\n",
    "# Calculate the group percentage error for each frequency factor\n",
    "group_percentage_errors = compute_group_percentage_error(urea, carb, co2, nh3, h2o, biuret, Reference_mass_frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the minimum error\n",
    "min_error_index = np.argmin(group_percentage_errors)\n",
    "min_error = group_percentage_errors[min_error_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urea mass fraction: 0.3323\n",
      "Carbamate mass fraction: 0.2418\n",
      "CO2 mass fraction: 0.0325\n",
      "NH3 mass fraciton: 0.2082\n",
      "H2O mass fraciton: 0.1710\n",
      "Biuret mass fraciton: 0.0031\n",
      "Error: 9.7274%\n",
      "k1: 3437.32\n",
      "k2: 14125.76\n",
      "k3: 425.94\n"
     ]
    }
   ],
   "source": [
    "print(f'Urea mass fraction: {urea[min_error_index]:.4f}')\n",
    "print(f'Carbamate mass fraction: {carb[min_error_index]:.4f}')\n",
    "print(f'CO2 mass fraction: {co2[min_error_index]:.4f}')\n",
    "print(f'NH3 mass fraciton: {nh3[min_error_index]:.4f}')\n",
    "print(f'H2O mass fraciton: {h2o[min_error_index]:.4f}')\n",
    "print(f'Biuret mass fraciton: {biuret[min_error_index]:.4f}')\n",
    "print(f'Error: {min_error:.4f}%')\n",
    "print(f'k1: {filtered_k_values[min_error_index][0]:.2f}')\n",
    "print(f'k2: {filtered_k_values[min_error_index][1]:.2f}')\n",
    "print(f'k3: {filtered_k_values[min_error_index][2]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sobol Sensitivity Indices:\n",
      "First Order Indices: [0.4940022  0.21842613 0.17041413]\n",
      "Total Order Indices: [0.59370564 0.29399177 0.24335776]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fit a surrogate model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(filtered_k_values, group_percentage_errors)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(X_new):\n",
    "    return model.predict(np.array(X_new).reshape(1, -1))\n",
    "\n",
    "# Generate samples\n",
    "param_values = saltelli.sample(factors, 1024)\n",
    "\n",
    "# Initialize an array for the outputs\n",
    "Y = np.zeros(param_values.shape[0])\n",
    "\n",
    "# Evaluate the surrogate model on the sampled inputs\n",
    "for i, X_sample in enumerate(param_values):\n",
    "    Y[i] = evaluate_model(X_sample)\n",
    "\n",
    "# Perform Sobol sensitivity analysis\n",
    "Si = sobol.analyze(factors, Y)\n",
    "\n",
    "# Display results\n",
    "print(\"Sobol Sensitivity Indices:\")\n",
    "print(\"First Order Indices:\", Si['S1'])\n",
    "print(\"Total Order Indices:\", Si['ST'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
